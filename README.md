* cuda has async execution --> profiling not so easy: https://discuss.pytorch.org/t/why-backward-and-optimizer-step-become-slower-with-jit-trace/162786
* info on memory management in r torch: https://torch.mlverse.org/docs/articles/memory-management
* info on torchscript: https://torch.mlverse.org/docs/articles/torchscript.html?q=TorchScr#compiling-torchscript
